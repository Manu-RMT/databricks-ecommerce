# ğŸ›’ Eâ€‘Commerce Lakehouse Pipeline (Databricks)

## ğŸ“Œ Introduction

Ce projet implÃ©mente une architecture **Lakehouse en mÃ©daillon (Bronze â†’ Silver â†’ Gold)** pour traiter un jeu de donnÃ©es eâ€‘commerce.  

Lâ€™objectif est de construire un pipeline complet, maintenable et orientÃ© BI, basÃ© sur :

- des notebooks Databricks orchestrÃ©s,

- des modules Python rÃ©utilisables,

- des tables Delta Lake optimisÃ©es pour lâ€™analyse,

- un modÃ¨le dimensionnel (dimensions + fait),

- un **dashboard Databricks** pour la visualisation finale.

---

## ğŸ—‚ï¸ Structure du Repository
 
 # ğŸ›’ Eâ€‘Commerce Lakehouse Pipeline (Databricks)

## ğŸ“Œ Introduction

Ce projet implÃ©mente une architecture **Lakehouse en mÃ©daillon (Bronze â†’ Silver â†’ Gold)** pour traiter un jeu de donnÃ©es eâ€‘commerce.  

Lâ€™objectif est de construire un pipeline complet, maintenable et orientÃ© BI, basÃ© sur :

- des notebooks Databricks orchestrÃ©s,

- des modules Python rÃ©utilisables,

- des tables Delta Lake optimisÃ©es pour lâ€™analyse,

- un modÃ¨le dimensionnel (dimensions + fait),

- un **dashboard Databricks** pour la visualisation finale.

---

## ğŸ—‚ï¸ Structure du Repository
 
 # ğŸ›’ Eâ€‘Commerce Lakehouse Pipeline (Databricks)

## ğŸ“Œ Introduction

Ce projet implÃ©mente une architecture **Lakehouse en mÃ©daillon (Bronze â†’ Silver â†’ Gold)** pour traiter un jeu de donnÃ©es eâ€‘commerce.  

Lâ€™objectif est de construire un pipeline complet, maintenable et orientÃ© BI, basÃ© sur :

- des notebooks Databricks orchestrÃ©s,

- des modules Python rÃ©utilisables,

- des tables Delta Lake optimisÃ©es pour lâ€™analyse,

- un modÃ¨le dimensionnel (dimensions + fait),

- un **dashboard Databricks** pour la visualisation finale.

---

## ğŸ—‚ï¸ Structure du Repository
 
 ![Image (7)_1770970611623.jpg](./Image (7)_1770970611623.jpg "Image (7)_1770970611623.jpg")
 
 ### ğŸ“ `lib/` â€” Modules Python
- **config.py** : centralisation des chemins, paramÃ¨tres, options Delta, constantes.
- **utils.py** : fonctions utilitaires (lecture/Ã©criture Delta, nettoyage, logs, SCD, etc.).
### ğŸ“ `notebooks/` â€” Pipeline Databricks
Chaque notebook correspond Ã  une Ã©tape du pipeline en mÃ©daillon.
---
# ğŸ§± Architecture en MÃ©daillon
## ğŸ¥‰ Bronze â€” Ingestion des donnÃ©es brutes
**Notebook :** `01_bronze_ingestion_data`
Tables ingÃ©rÃ©es :
- brands  
- categories  
- customers  
- order_items  
- products  
**Principes :**
- ingestion *as-is*
- ajout de colonnes techniques (`ingestion_ts`, `source_file`)
- stockage en Delta Lake
- schÃ©ma brut conservÃ©
---
## ğŸ¥ˆ Silver â€” Nettoyage & Normalisation
**Notebook :** `02_silver_transformation`
Transformations appliquÃ©es :
- nettoyage des chaÃ®nes (trim, accents, caractÃ¨res spÃ©ciaux)
- normalisation des formats (dates, types, majuscules/minuscules)
- gestion des doublons
- harmonisation des clÃ©s
- ajout de colonnes de traÃ§abilitÃ© :
 - `insert_ts`
 - `update_ts`
 - `is_current`
Tables Silver gÃ©nÃ©rÃ©es :
- `slv_ecommerce_brands`
- `slv_ecommerce_categories`
- `slv_ecommerce_customers`
- `slv_ecommerce_order_items`
- `slv_ecommerce_products`
---
## ğŸ¥‡ Gold â€” ModÃ¨le Dimensionnel
### ğŸ“˜ Dimensions
**Notebook :** `03_gold_dimensions_tables`
Tables crÃ©Ã©es :
- `dim_ecommerce_customers`
- `dim_ecommerce_products`
- `dim_ecommerce_brands`
- `dim_ecommerce_categories`
CaractÃ©ristiques :
- clÃ©s substituts
- colonnes business enrichies
- gestion SCD si nÃ©cessaire
- tables optimisÃ©es pour la BI
---
### ğŸ“— Faits
**Notebook :** `03_gold_facts_table`
Table crÃ©Ã©e :
- `fact_ecommerce_order_items`
Grain : **ligne dâ€™article dâ€™une commande**
Contenu :
- clÃ©s Ã©trangÃ¨res vers les dimensions
- mesures : quantitÃ©, prix unitaire, montant total
- dates de commande / livraison
- optimisation Delta (Zâ€‘Order, partitionnement si pertinent)
---
# ğŸ“Š Dashboard Databricks â€” Visualisation Finale
Un **dashboard Databricks** est construit Ã  partir des tables Gold afin de fournir une vue analytique complÃ¨te de lâ€™activitÃ© eâ€‘commerce.
### Indicateurs clÃ©s :
- Total des ventes  
- Nombre de commandes  
- QuantitÃ© vendue par produit  
- Top catÃ©gories / top marques  
- Analyse clients (segmentation, rÃ©currence, panier moyen)  
- Analyse temporelle (jour, mois, annÃ©e)
### Sources du dashboard :
- `fact_ecommerce_order_items`
- `dim_ecommerce_products`
- `dim_ecommerce_customers`
- `dim_ecommerce_brands`
- `dim_ecommerce_categories`
Le dashboard permet une **analyse interactive** directement dans Databricks SQL.
---
# âš™ï¸ Notebook 00 â€” Setup & Initialisation
**Notebook :** `00_setup`
RÃ´le :
- crÃ©ation des zones `/bronze`, `/silver`, `/gold`
- configuration des paramÃ¨tres globaux
- import des modules Python (`config`, `utils`)
- vÃ©rification de lâ€™environnement
---
# ğŸ” Notebook â€” Queries Silver Zone
Notebook dÃ©diÃ© Ã  lâ€™exploration et la validation des tables Silver :
- profiling
- contrÃ´les qualitÃ©
- vÃ©rification des relations
- tests de cohÃ©rence
---
# ğŸš€ Workflow dâ€™ExÃ©cution
1. **00_setup**
2. **01_bronze_ingestion_data**
3. **02_silver_transformation**
4. **03_gold_dimensions_tables**
5. **03_gold_facts_table**
6. **Dashboard Databricks (visualisation finale)**
---
# ğŸ¯ Objectifs du Projet
- Construire un pipeline **fiable, traÃ§able et maintenable**
- Appliquer les bonnes pratiques du **Delta Lake**
- Produire un modÃ¨le **dimensionnel** prÃªt pour lâ€™analyse
- Fournir un **dashboard analytique** pour la prise de dÃ©cision
- Faciliter lâ€™intÃ©gration avec des outils BI
---
 
 